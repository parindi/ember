{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/parindi/ember/blob/master/Task1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lwk52yELeIvD"
      },
      "source": [
        "# Deep Neural Network Model on EMBER Malware Dataset:\n",
        "\n",
        "The EMBER dataset is a collection of features from PE files that serve as a benchmark dataset for researchers. <br>\n",
        "In this notebook, the EMBER-2017 v2 dataset is used which contains features from 1.1 million PE files scanned in or before 2017."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eyXmUXtlQma"
      },
      "source": [
        "# Importing required modules\n",
        "\n",
        "import pandas as pd"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vEqRxmdlWO5V"
      },
      "source": [
        "## Dataset Extraction:\n",
        "To use the dataset in this notebook, simple download and upload didn't work as the URL to download the dataset is detected as untrused by Google. So, downloading the EMBER 2017 v2 dataset to Colab notebook using wget command and double unzipping it to get the"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOIiSwMrcLye",
        "outputId": "ca6e9508-33ed-4cf8-d364-2d77f3117e5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "!wget https://ember.elastic.co/ember_dataset_2018_2.tar.bz2 --no-check-certificate"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-11-27 14:30:00--  https://ember.elastic.co/ember_dataset_2018_2.tar.bz2\n",
            "Resolving ember.elastic.co (ember.elastic.co)... 34.107.161.234, 2600:1901:0:1f6d::\n",
            "Connecting to ember.elastic.co (ember.elastic.co)|34.107.161.234|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1696539273 (1.6G) [application/x-bzip2]\n",
            "Saving to: ‘ember_dataset_2018_2.tar.bz2’\n",
            "\n",
            "ember_dataset_2018_ 100%[===================>]   1.58G  35.6MB/s    in 47s     \n",
            "\n",
            "2023-11-27 14:30:48 (34.1 MB/s) - ‘ember_dataset_2018_2.tar.bz2’ saved [1696539273/1696539273]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TGf1T6E6eGwM"
      },
      "source": [
        "# Decompressing a .bz2 file\n",
        "!bzip2 -d ember_dataset_2018_2.tar.bz2"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9rMLNJBJdZRK",
        "outputId": "964b5cb9-7e48-4432-c8ed-fc321aec2d83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "# Extracting from tar file\n",
        "!tar -xvf ember_dataset_2018_2.tar"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ember2018/\n",
            "ember2018/train_features_1.jsonl\n",
            "ember2018/train_features_0.jsonl\n",
            "ember2018/train_features_3.jsonl\n",
            "ember2018/test_features.jsonl\n",
            "ember2018/ember_model_2018.txt\n",
            "ember2018/train_features_5.jsonl\n",
            "ember2018/train_features_4.jsonl\n",
            "ember2018/train_features_2.jsonl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tlnm_lzgkCMH"
      },
      "source": [
        "All the required dataset files are extracted."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VGa3ZuR5gYXM"
      },
      "source": [
        "Now to work with the EMBER dataset, we need to clone its github repository whihc can be done by following code:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8aZDlrOhf7F",
        "outputId": "107aaa03-2e89-4030-d32f-24cee2f26898",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "!git clone https://github.com/elastic/ember"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ember'...\n",
            "remote: Enumerating objects: 285, done.\u001b[K\n",
            "remote: Counting objects: 100% (93/93), done.\u001b[K\n",
            "remote: Compressing objects: 100% (65/65), done.\u001b[K\n",
            "remote: Total 285 (delta 40), reused 70 (delta 28), pack-reused 192\u001b[K\n",
            "Receiving objects: 100% (285/285), 11.36 MiB | 22.38 MiB/s, done.\n",
            "Resolving deltas: 100% (121/121), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vrdHctlgYCr"
      },
      "source": [
        "!mv ember ember-master"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltF44yxegVzh"
      },
      "source": [
        "!cp -r ember-master/* ."
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZR3VMwDmt6bP",
        "outputId": "0b17370a-1fdd-4c87-d9da-9da96012d7ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "!pip install -r requirements_notebook.txt\n",
        "!python setup.py install"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting jupyter>=1.0.0 (from -r requirements_notebook.txt (line 1))\n",
            "  Downloading jupyter-1.0.0-py2.py3-none-any.whl (2.7 kB)\n",
            "Collecting vega>=2.5 (from -r requirements_notebook.txt (line 2))\n",
            "  Downloading vega-4.0.0-py3-none-any.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: vega_datasets>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements_notebook.txt (line 3)) (0.9.0)\n",
            "Requirement already satisfied: altair>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements_notebook.txt (line 4)) (4.2.2)\n",
            "Requirement already satisfied: matplotlib>=3.1.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements_notebook.txt (line 5)) (3.7.1)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.10/dist-packages (from jupyter>=1.0.0->-r requirements_notebook.txt (line 1)) (6.5.5)\n",
            "Collecting qtconsole (from jupyter>=1.0.0->-r requirements_notebook.txt (line 1))\n",
            "  Downloading qtconsole-5.5.1-py3-none-any.whl (123 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.4/123.4 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jupyter-console in /usr/local/lib/python3.10/dist-packages (from jupyter>=1.0.0->-r requirements_notebook.txt (line 1)) (6.1.0)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.10/dist-packages (from jupyter>=1.0.0->-r requirements_notebook.txt (line 1)) (6.5.4)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.10/dist-packages (from jupyter>=1.0.0->-r requirements_notebook.txt (line 1)) (5.5.6)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.10/dist-packages (from jupyter>=1.0.0->-r requirements_notebook.txt (line 1)) (7.7.1)\n",
            "Collecting ipytablewidgets<0.4.0,>=0.3.0 (from vega>=2.5->-r requirements_notebook.txt (line 2))\n",
            "  Downloading ipytablewidgets-0.3.1-py2.py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.2/190.2 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas<2.0.0,>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from vega>=2.5->-r requirements_notebook.txt (line 2)) (1.5.3)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair>=3.1.0->-r requirements_notebook.txt (line 4)) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair>=3.1.0->-r requirements_notebook.txt (line 4)) (3.1.2)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair>=3.1.0->-r requirements_notebook.txt (line 4)) (4.19.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from altair>=3.1.0->-r requirements_notebook.txt (line 4)) (1.23.5)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair>=3.1.0->-r requirements_notebook.txt (line 4)) (0.12.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.1->-r requirements_notebook.txt (line 5)) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.1->-r requirements_notebook.txt (line 5)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.1->-r requirements_notebook.txt (line 5)) (4.44.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.1->-r requirements_notebook.txt (line 5)) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.1->-r requirements_notebook.txt (line 5)) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.1->-r requirements_notebook.txt (line 5)) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.1->-r requirements_notebook.txt (line 5)) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.1->-r requirements_notebook.txt (line 5)) (2.8.2)\n",
            "Requirement already satisfied: traitlets>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from ipytablewidgets<0.4.0,>=0.3.0->vega>=2.5->-r requirements_notebook.txt (line 2)) (5.7.1)\n",
            "Requirement already satisfied: traittypes>=0.0.6 in /usr/local/lib/python3.10/dist-packages (from ipytablewidgets<0.4.0,>=0.3.0->vega>=2.5->-r requirements_notebook.txt (line 2)) (0.2.1)\n",
            "Collecting lz4 (from ipytablewidgets<0.4.0,>=0.3.0->vega>=2.5->-r requirements_notebook.txt (line 2))\n",
            "  Downloading lz4-4.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->jupyter>=1.0.0->-r requirements_notebook.txt (line 1)) (0.2.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->jupyter>=1.0.0->-r requirements_notebook.txt (line 1)) (3.6.6)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->jupyter>=1.0.0->-r requirements_notebook.txt (line 1)) (7.34.0)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->jupyter>=1.0.0->-r requirements_notebook.txt (line 1)) (3.0.9)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyter>=1.0.0->-r requirements_notebook.txt (line 1)) (6.1.12)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyter>=1.0.0->-r requirements_notebook.txt (line 1)) (6.3.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair>=3.1.0->-r requirements_notebook.txt (line 4)) (23.1.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair>=3.1.0->-r requirements_notebook.txt (line 4)) (2023.11.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair>=3.1.0->-r requirements_notebook.txt (line 4)) (0.31.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair>=3.1.0->-r requirements_notebook.txt (line 4)) (0.13.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.0.0,>=1.5.0->vega>=2.5->-r requirements_notebook.txt (line 2)) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.1.1->-r requirements_notebook.txt (line 5)) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair>=3.1.0->-r requirements_notebook.txt (line 4)) (2.1.3)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-console->jupyter>=1.0.0->-r requirements_notebook.txt (line 1)) (3.0.41)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from jupyter-console->jupyter>=1.0.0->-r requirements_notebook.txt (line 1)) (2.16.1)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter>=1.0.0->-r requirements_notebook.txt (line 1)) (4.9.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter>=1.0.0->-r requirements_notebook.txt (line 1)) (4.11.2)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter>=1.0.0->-r requirements_notebook.txt (line 1)) (6.1.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter>=1.0.0->-r requirements_notebook.txt (line 1)) (0.7.1)\n",
            "Requirement already satisfied: jupyter-core>=4.7 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter>=1.0.0->-r requirements_notebook.txt (line 1)) (5.5.0)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter>=1.0.0->-r requirements_notebook.txt (line 1)) (0.2.2)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter>=1.0.0->-r requirements_notebook.txt (line 1)) (0.8.4)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter>=1.0.0->-r requirements_notebook.txt (line 1)) (0.9.0)\n",
            "Requirement already satisfied: nbformat>=5.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter>=1.0.0->-r requirements_notebook.txt (line 1)) (5.9.2)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter>=1.0.0->-r requirements_notebook.txt (line 1)) (1.5.0)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter>=1.0.0->-r requirements_notebook.txt (line 1)) (1.2.1)\n",
            "Requirement already satisfied: pyzmq<25,>=17 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter>=1.0.0->-r requirements_notebook.txt (line 1)) (23.2.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter>=1.0.0->-r requirements_notebook.txt (line 1)) (23.1.0)\n",
            "Requirement already satisfied: nest-asyncio>=1.5 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter>=1.0.0->-r requirements_notebook.txt (line 1)) (1.5.8)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter>=1.0.0->-r requirements_notebook.txt (line 1)) (1.8.2)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter>=1.0.0->-r requirements_notebook.txt (line 1)) (0.18.0)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter>=1.0.0->-r requirements_notebook.txt (line 1)) (0.18.0)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter>=1.0.0->-r requirements_notebook.txt (line 1)) (1.0.0)\n",
            "Collecting qtpy>=2.4.0 (from qtconsole->jupyter>=1.0.0->-r requirements_notebook.txt (line 1))\n",
            "  Downloading QtPy-2.4.1-py3-none-any.whl (93 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.5/93.5 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets->jupyter>=1.0.0->-r requirements_notebook.txt (line 1)) (67.7.2)\n",
            "Collecting jedi>=0.16 (from ipython>=4.0.0->ipywidgets->jupyter>=1.0.0->-r requirements_notebook.txt (line 1))\n",
            "  Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m52.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets->jupyter>=1.0.0->-r requirements_notebook.txt (line 1)) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets->jupyter>=1.0.0->-r requirements_notebook.txt (line 1)) (0.7.5)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets->jupyter>=1.0.0->-r requirements_notebook.txt (line 1)) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets->jupyter>=1.0.0->-r requirements_notebook.txt (line 1)) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets->jupyter>=1.0.0->-r requirements_notebook.txt (line 1)) (4.8.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core>=4.7->nbconvert->jupyter>=1.0.0->-r requirements_notebook.txt (line 1)) (4.0.0)\n",
            "Requirement already satisfied: jupyter-server>=1.8 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook->jupyter>=1.0.0->-r requirements_notebook.txt (line 1)) (1.24.0)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook->jupyter>=1.0.0->-r requirements_notebook.txt (line 1)) (0.2.3)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.1->nbconvert->jupyter>=1.0.0->-r requirements_notebook.txt (line 1)) (2.19.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->jupyter-console->jupyter>=1.0.0->-r requirements_notebook.txt (line 1)) (0.2.10)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.10/dist-packages (from terminado>=0.8.3->notebook->jupyter>=1.0.0->-r requirements_notebook.txt (line 1)) (0.7.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->notebook->jupyter>=1.0.0->-r requirements_notebook.txt (line 1)) (21.2.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert->jupyter>=1.0.0->-r requirements_notebook.txt (line 1)) (2.5)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->nbconvert->jupyter>=1.0.0->-r requirements_notebook.txt (line 1)) (0.5.1)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets->jupyter>=1.0.0->-r requirements_notebook.txt (line 1)) (0.8.3)\n",
            "Requirement already satisfied: anyio<4,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter>=1.0.0->-r requirements_notebook.txt (line 1)) (3.7.1)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter>=1.0.0->-r requirements_notebook.txt (line 1)) (1.6.4)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook->jupyter>=1.0.0->-r requirements_notebook.txt (line 1)) (1.16.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter>=1.0.0->-r requirements_notebook.txt (line 1)) (3.4)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter>=1.0.0->-r requirements_notebook.txt (line 1)) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter>=1.0.0->-r requirements_notebook.txt (line 1)) (1.1.3)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook->jupyter>=1.0.0->-r requirements_notebook.txt (line 1)) (2.21)\n",
            "Installing collected packages: qtpy, lz4, jedi, qtconsole, jupyter, ipytablewidgets, vega\n",
            "Successfully installed ipytablewidgets-0.3.1 jedi-0.19.1 jupyter-1.0.0 lz4-4.3.2 qtconsole-5.5.1 qtpy-2.4.1 vega-4.0.0\n",
            "running install\n",
            "/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/cmd.py:66: SetuptoolsDeprecationWarning: setup.py install is deprecated.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Please avoid running ``setup.py`` directly.\n",
            "        Instead, use pypa/build, pypa/installer, pypa/build or\n",
            "        other standards-based tools.\n",
            "\n",
            "        See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  self.initialize_options()\n",
            "/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/cmd.py:66: EasyInstallDeprecationWarning: easy_install command is deprecated.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Please avoid running ``setup.py`` and ``easy_install``.\n",
            "        Instead, use pypa/build, pypa/installer, pypa/build or\n",
            "        other standards-based tools.\n",
            "\n",
            "        See https://github.com/pypa/setuptools/issues/917 for details.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  self.initialize_options()\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "creating ember.egg-info\n",
            "writing ember.egg-info/PKG-INFO\n",
            "writing dependency_links to ember.egg-info/dependency_links.txt\n",
            "writing top-level names to ember.egg-info/top_level.txt\n",
            "writing manifest file 'ember.egg-info/SOURCES.txt'\n",
            "reading manifest file 'ember.egg-info/SOURCES.txt'\n",
            "adding license file 'LICENSE.txt'\n",
            "writing manifest file 'ember.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "running build_py\n",
            "creating build\n",
            "creating build/lib\n",
            "creating build/lib/ember\n",
            "copying ember/features.py -> build/lib/ember\n",
            "copying ember/__init__.py -> build/lib/ember\n",
            "creating build/bdist.linux-x86_64\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "creating build/bdist.linux-x86_64/egg/ember\n",
            "copying build/lib/ember/features.py -> build/bdist.linux-x86_64/egg/ember\n",
            "copying build/lib/ember/__init__.py -> build/bdist.linux-x86_64/egg/ember\n",
            "byte-compiling build/bdist.linux-x86_64/egg/ember/features.py to features.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/ember/__init__.py to __init__.cpython-310.pyc\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying ember.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying ember.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying ember.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying ember.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "creating dist\n",
            "creating 'dist/ember-0.1.0-py3.10.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing ember-0.1.0-py3.10.egg\n",
            "Copying ember-0.1.0-py3.10.egg to /usr/local/lib/python3.10/dist-packages\n",
            "Adding ember 0.1.0 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.10/dist-packages/ember-0.1.0-py3.10.egg\n",
            "Processing dependencies for ember==0.1.0\n",
            "Finished processing dependencies for ember==0.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lief"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "SHAhJJLpuELz",
        "outputId": "99353066-e732-46bc-ab87-f1fdfab978f8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting lief\n",
            "  Downloading lief-0.13.2-cp310-cp310-manylinux_2_24_x86_64.whl (4.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: lief\n",
            "Successfully installed lief-0.13.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N0Cr_zbZWEw_"
      },
      "source": [
        "The LIEF project is used to extract features from PE files included in the EMBER dataset. Raw features are extracted to JSON format. Vectorized features can be produced from these raw features and saved in binary format from which they can be converted to CSV, dataframe, or any other format."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQJgzku0t7hy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "78087706-40ae-40be-eecf-825b8293df74"
      },
      "source": [
        "import ember\n",
        "ember.create_vectorized_features(\"/content/ember2018/\")\n",
        "ember.create_metadata(\"/content/ember2018/\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: EMBER feature version 2 were computed using lief version 0.9.0-\n",
            "WARNING:   lief version 0.13.2-2d9855fc found instead. There may be slight inconsistencies\n",
            "WARNING:   in the feature calculations.\n",
            "Vectorizing training set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 800000/800000 [44:57<00:00, 296.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vectorizing test set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200000/200000 [11:00<00:00, 302.95it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   sha256 appeared  label  \\\n",
              "0       0abb4fda7d5b13801d63bee53e5e256be43e141faa077a...  2006-12      0   \n",
              "1       c9cafff8a596ba8a80bafb4ba8ae6f2ef3329d95b85f15...  2007-01      0   \n",
              "2       eac8ddb4970f8af985742973d6f0e06902d42a3684d791...  2007-02      0   \n",
              "3       7f513818bcc276c531af2e641c597744da807e21cc1160...  2007-02      0   \n",
              "4       ca65e1c387a4cc9e7d8a8ce12bf1bcf9f534c9032b9d95...  2007-02      0   \n",
              "...                                                   ...      ...    ...   \n",
              "999995  e033bc4967ce64bbb5cafdb234372099395185a6e0280c...  2018-12      1   \n",
              "999996  c7d16736fd905f5fbe4530670b1fe787eb12ee86536380...  2018-12      1   \n",
              "999997  0020077cb673729209d88b603bddf56b925b18e682892a...  2018-12      0   \n",
              "999998  1b7e7c8febabf70d1c17fe3c7abf80f33003581c380f28...  2018-12      0   \n",
              "999999  836063f2312b597632bca1f738e68e4d23f672d587a7fc...  2018-12      1   \n",
              "\n",
              "          avclass subset  \n",
              "0                  train  \n",
              "1                  train  \n",
              "2                  train  \n",
              "3                  train  \n",
              "4                  train  \n",
              "...           ...    ...  \n",
              "999995       zbot   test  \n",
              "999996  flystudio   test  \n",
              "999997              test  \n",
              "999998              test  \n",
              "999999     emotet   test  \n",
              "\n",
              "[1000000 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3063b6a9-634f-4c7c-8080-7e250d746b28\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sha256</th>\n",
              "      <th>appeared</th>\n",
              "      <th>label</th>\n",
              "      <th>avclass</th>\n",
              "      <th>subset</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0abb4fda7d5b13801d63bee53e5e256be43e141faa077a...</td>\n",
              "      <td>2006-12</td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>c9cafff8a596ba8a80bafb4ba8ae6f2ef3329d95b85f15...</td>\n",
              "      <td>2007-01</td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>eac8ddb4970f8af985742973d6f0e06902d42a3684d791...</td>\n",
              "      <td>2007-02</td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7f513818bcc276c531af2e641c597744da807e21cc1160...</td>\n",
              "      <td>2007-02</td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ca65e1c387a4cc9e7d8a8ce12bf1bcf9f534c9032b9d95...</td>\n",
              "      <td>2007-02</td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999995</th>\n",
              "      <td>e033bc4967ce64bbb5cafdb234372099395185a6e0280c...</td>\n",
              "      <td>2018-12</td>\n",
              "      <td>1</td>\n",
              "      <td>zbot</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999996</th>\n",
              "      <td>c7d16736fd905f5fbe4530670b1fe787eb12ee86536380...</td>\n",
              "      <td>2018-12</td>\n",
              "      <td>1</td>\n",
              "      <td>flystudio</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999997</th>\n",
              "      <td>0020077cb673729209d88b603bddf56b925b18e682892a...</td>\n",
              "      <td>2018-12</td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999998</th>\n",
              "      <td>1b7e7c8febabf70d1c17fe3c7abf80f33003581c380f28...</td>\n",
              "      <td>2018-12</td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999999</th>\n",
              "      <td>836063f2312b597632bca1f738e68e4d23f672d587a7fc...</td>\n",
              "      <td>2018-12</td>\n",
              "      <td>1</td>\n",
              "      <td>emotet</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000000 rows × 5 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3063b6a9-634f-4c7c-8080-7e250d746b28')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3063b6a9-634f-4c7c-8080-7e250d746b28 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3063b6a9-634f-4c7c-8080-7e250d746b28');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-9c67109f-99f0-49ce-9e5d-fc4508fa21b5\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9c67109f-99f0-49ce-9e5d-fc4508fa21b5')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-9c67109f-99f0-49ce-9e5d-fc4508fa21b5 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R6J-vmo77zYH",
        "outputId": "d235dd55-9948-4fec-f57e-872a824d2463",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "import ember\n",
        "data_path = '/content/ember2018/'\n",
        "emberdf = ember.read_metadata(data_path)\n",
        "emberdf.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              sha256 appeared  label avclass  \\\n",
              "0  0abb4fda7d5b13801d63bee53e5e256be43e141faa077a...  2006-12      0     NaN   \n",
              "1  c9cafff8a596ba8a80bafb4ba8ae6f2ef3329d95b85f15...  2007-01      0     NaN   \n",
              "2  eac8ddb4970f8af985742973d6f0e06902d42a3684d791...  2007-02      0     NaN   \n",
              "3  7f513818bcc276c531af2e641c597744da807e21cc1160...  2007-02      0     NaN   \n",
              "4  ca65e1c387a4cc9e7d8a8ce12bf1bcf9f534c9032b9d95...  2007-02      0     NaN   \n",
              "\n",
              "  subset  \n",
              "0  train  \n",
              "1  train  \n",
              "2  train  \n",
              "3  train  \n",
              "4  train  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-31184ae3-99c2-4e21-80c5-9ba4d59f731c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sha256</th>\n",
              "      <th>appeared</th>\n",
              "      <th>label</th>\n",
              "      <th>avclass</th>\n",
              "      <th>subset</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0abb4fda7d5b13801d63bee53e5e256be43e141faa077a...</td>\n",
              "      <td>2006-12</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>c9cafff8a596ba8a80bafb4ba8ae6f2ef3329d95b85f15...</td>\n",
              "      <td>2007-01</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>eac8ddb4970f8af985742973d6f0e06902d42a3684d791...</td>\n",
              "      <td>2007-02</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7f513818bcc276c531af2e641c597744da807e21cc1160...</td>\n",
              "      <td>2007-02</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ca65e1c387a4cc9e7d8a8ce12bf1bcf9f534c9032b9d95...</td>\n",
              "      <td>2007-02</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-31184ae3-99c2-4e21-80c5-9ba4d59f731c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-31184ae3-99c2-4e21-80c5-9ba4d59f731c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-31184ae3-99c2-4e21-80c5-9ba4d59f731c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-7a0ad50d-a24d-49e6-852c-6b16ac598643\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7a0ad50d-a24d-49e6-852c-6b16ac598643')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-7a0ad50d-a24d-49e6-852c-6b16ac598643 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DhATFqoa81qR",
        "outputId": "36a8da00-512e-4528-dbed-6280942f652a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "X_train0, y_train0, X_test0, y_test0 = ember.read_vectorized_features(data_path)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: EMBER feature version 2 were computed using lief version 0.9.0-\n",
            "WARNING:   lief version 0.13.2-2d9855fc found instead. There may be slight inconsistencies\n",
            "WARNING:   in the feature calculations.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LX3zlnp6bBH9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "9d8ccbcc-6683-4e65-85c0-1d739bac4729"
      },
      "source": [
        "X_train0"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "memmap([[1.4676122e-02, 4.2218715e-03, 3.9226813e-03, ..., 0.0000000e+00,\n",
              "         0.0000000e+00, 0.0000000e+00],\n",
              "        [1.8452372e-01, 3.1307504e-02, 5.6928140e-03, ..., 4.4229600e+05,\n",
              "         0.0000000e+00, 0.0000000e+00],\n",
              "        [2.5173673e-01, 1.4204546e-02, 6.8414863e-03, ..., 3.7280000e+04,\n",
              "         0.0000000e+00, 0.0000000e+00],\n",
              "        ...,\n",
              "        [1.4297070e-01, 8.6626979e-03, 4.2015705e-03, ..., 0.0000000e+00,\n",
              "         0.0000000e+00, 0.0000000e+00],\n",
              "        [1.4780925e-01, 6.4021470e-03, 5.1157344e-03, ..., 0.0000000e+00,\n",
              "         0.0000000e+00, 0.0000000e+00],\n",
              "        [1.3445158e-01, 6.8144272e-03, 5.5496283e-03, ..., 0.0000000e+00,\n",
              "         0.0000000e+00, 0.0000000e+00]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZhOHnFA88Z-",
        "outputId": "b357beb2-37f3-4266-eb6e-cc013bc8063f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "#shape of the dataset\n",
        "X_train0.shape, y_train0.shape, X_test0.shape, y_test0.shape"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((800000, 2381), (800000,), (200000, 2381), (200000,))"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XexOgKaqkfZ_"
      },
      "source": [
        "## Data Preprocessing:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bjmcemBkkd67"
      },
      "source": [
        "It is known that the EMBER train dataset has three sample categories, namels unlabled, benign and malicious. They are represented as -1, 0 and 1 respectively. But it can be seen that the test dataset has only benign and malicious samples. In this project, I am ignoring the unlabled samples from the train dataset for the better performance of the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YrX0zh4gOoqT",
        "outputId": "5abfa03a-de44-4d00-a67d-3324693bb2fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "import pandas as pd\n",
        "# Creating dataframes of X_train & y_train\n",
        "X_train0 = pd.DataFrame(X_train0)\n",
        "y_train0 = pd.DataFrame(y_train0)\n",
        "X_train0.shape, y_train0.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((800000, 2381), (800000, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wrUqD29-Ukuz",
        "outputId": "faeb42e0-8280-4425-bf18-1b64511eabb2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "#Unique labels in the train dataset\n",
        "y_train0[0].unique()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.,  1., -1.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9DJTT2wZDU-",
        "outputId": "ae67d756-a1d6-4b81-82ea-4fc221e489e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "# Combining features and lables of train dataset\n",
        "X_train0[2381] = y_train0[0]\n",
        "X_train0.shape, y_train0.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((800000, 2382), (800000, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3s_F9dYZqpZ",
        "outputId": "5e86e468-72cc-433c-9379-fda04440c595",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "#Checking the presence of unique lables in the combined dataframe\n",
        "X_train0[2381].unique()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.,  1., -1.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFqNvoNxiGQX",
        "outputId": "064f7f34-1433-43c4-db36-103ab2390ae2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "X_train0.shape, y_train0.shape"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((800000, 2382), (800000, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_JZZs4MwXXgi"
      },
      "source": [
        "The dataset is huge and takes lot to time for vectorizing and creating metadata for every runtime execution. So, create pickle files for the training and testing samples to store them in the system. By downloading and storing these pickle files, one can avoid the execution of the former lines of code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xGtAaozdr9R"
      },
      "source": [
        "#Pickling the datasets\n",
        "pd.DataFrame(X_train0).to_pickle(\"./X_train.pkl\")\n",
        "pd.DataFrame(y_train0).to_pickle(\"./y_train.pkl\")\n",
        "pd.DataFrame(X_test0).to_pickle(\"./X_test.pkl\")\n",
        "pd.DataFrame(y_test0).to_pickle(\"./y_test.pkl\")"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "ek08sIYODSfI",
        "outputId": "bfe397cb-86da-46c2-c54c-c77e4f859243"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MkPA_DWw5T3k"
      },
      "source": [
        "I faced network failure error while downloading the pickle file to store it in my system. The alternate solution for this error is to upload the pickle files to the Google Drive by executing the following code:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGz-025xs8uW",
        "outputId": "1c30bb06-25e5-49ed-e933-576f81e3bff4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFleRQU8uG8L"
      },
      "source": [
        "# Copying pickle files to Google Drive\n",
        "!cp ./X_test.pkl ./gdrive/My\\ Drive/Pickle_Files/\n",
        "!cp ./y_test.pkl ./gdrive/My\\ Drive/Pickle_Files/\n",
        "!cp ./X_train.pkl ./gdrive/My\\ Drive/Pickle_Files/\n",
        "!cp ./y_train.pkl ./gdrive/My\\ Drive/Pickle_Files/"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pnczpAhUzMD7"
      },
      "source": [
        "# Extracting training data from pickle files\n",
        "import pandas as pd\n",
        "X_trainp = pd.read_pickle(\"/content/gdrive/My Drive/Pickle_Files/X_train.pkl\")\n",
        "y_trainp = pd.read_pickle(\"/content/gdrive/My Drive/Pickle_Files/y_train.pkl\")"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zb7CB5cBQwj6"
      },
      "source": [
        "# Extracting testing data from pickle files\n",
        "X_testp =pd.read_pickle(\"/content/gdrive/My Drive/Pickle_Files/X_test.pkl\")\n",
        "y_testp = pd.read_pickle(\"/content/gdrive/My Drive/Pickle_Files/y_test.pkl\")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E1UyM8a00pmM",
        "outputId": "af3a7231-5e6d-41cc-ea93-e79a51bbf2dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "#Shape of the dataset\n",
        "X_trainp.shape, y_trainp.shape, X_testp.shape, y_testp.shape"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((800000, 2382), (800000, 1), (200000, 2381), (200000, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sK89OZPAZ3YJ"
      },
      "source": [
        "At this point of execution, I can see that the above lines of code used most of the 12GB RAM availbale in Colab. So, even though the datasets are pickled, the RAM crashes. The alternative for this is to create HDF5 files. The h5py package is a Pythonic interface to the HDF5 binary data format."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZRZoyXPZ2Rn"
      },
      "source": [
        "import h5py\n",
        "\n",
        "# Loading X_train data to HDF5 file\n",
        "h50 = h5py.File('X_train0.h5', 'w')\n",
        "h50.create_dataset('X_train0', data=X_train0)\n",
        "h50.close()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdmoZhq1E_Tj"
      },
      "source": [
        "# Loading y_train data to HDF5 file\n",
        "h51 = h5py.File('y_train0.h5', 'w')\n",
        "h51.create_dataset('y_train0', data=y_train0)\n",
        "h51.close()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mX5vRvd4FX5E"
      },
      "source": [
        "#Loading X_test data to HDF5 file\n",
        "h52 = h5py.File('X_test0.h5', 'w')\n",
        "h52.create_dataset('X_test0', data=X_test0)\n",
        "h52.close()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NSN1YzZFKsI"
      },
      "source": [
        "#Loading y_test data to HDF5 file\n",
        "h53 = h5py.File('y_test0.h5', 'w')\n",
        "h53.create_dataset('y_test0', data=y_test0)\n",
        "h53.close()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_OnOivjSg_0"
      },
      "source": [
        "#Storing all the h5 files to GDrive\n",
        "!cp ./X_train0.h5 ./gdrive/My\\ Drive/Pickle_Files\n",
        "!cp ./y_train0.h5 ./gdrive/My\\ Drive/Pickle_Files\n",
        "!cp ./X_test0.h5 ./gdrive/My\\ Drive/Pickle_Files\n",
        "!cp ./y_test0.h5 ./gdrive/My\\ Drive/Pickle_Files"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQNvZBLVLHV-",
        "outputId": "ffdd0646-9f73-4ac0-d497-c7f554117298",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "#reading the X_train data from h5 files\n",
        "import h5py\n",
        "Xh5 = h5py.File('/content/gdrive/My Drive/Pickle_Files/X_train0.h5','r')\n",
        "X_train = Xh5['X_train0']\n",
        "X_train.shape"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(800000, 2381)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QvCiIwcRLmRK",
        "outputId": "f4cab46d-c80b-4dcf-d05d-a5d4464836bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "# Reading y_train data from h5 files\n",
        "import h5py\n",
        "yh5 = h5py.File('/content/gdrive/My Drive/Pickle_Files/y_train0.h5','r')\n",
        "y_train = yh5['y_train0']\n",
        "y_train.shape"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(800000,)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_9RdRv0asUh",
        "outputId": "556b6d5b-c36b-42df-87cd-d2ba65fe560c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "# Reading X_test data from h5 files\n",
        "import h5py\n",
        "Xth5 = h5py.File('/content/gdrive/My Drive/Pickle_Files/X_test0.h5','r')\n",
        "X_test = Xth5['X_test0']\n",
        "X_test.shape"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(200000, 2381)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3DvD6F6QasIN",
        "outputId": "d58a827d-38e0-4b7b-9a36-4bce61630dc9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "# Reading y_test data from h5 files\n",
        "import h5py\n",
        "yth5 = h5py.File('/content/gdrive/My Drive/Pickle_Files/y_test0.h5','r')\n",
        "y_test = yth5['y_test0']\n",
        "y_test.shape"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(200000,)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7iepfIOI3FC"
      },
      "source": [
        "**The features of this dataset are scaled on different scalars and among them I picked RobustScalar to do the feature scaling.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2MVL53fHFXa"
      },
      "source": [
        "# Scaling the features inorder to improve the performance of the model\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "\n",
        "rs = RobustScaler()\n",
        "Xtrain_rs = rs.fit_transform(X_train)\n",
        "Xtest_rs = rs.fit_transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YrHijvhMpcBd"
      },
      "source": [
        "#Loading scaled X_train data to HDF5 file\n",
        "h54 = h5py.File('Xtrain_rs.h5', 'w')\n",
        "h54.create_dataset('Xtrain_rs', data=Xtrain_rs)\n",
        "h54.close()\n",
        "\n",
        "#Storing the h5 files to GDrive\n",
        "!cp ./Xtrain_rs.h5 ./gdrive/My\\ Drive/Pickle_Files"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r5Fdt27vpADT"
      },
      "source": [
        "#Loading scaled X_test data to HDF5 file\n",
        "h55 = h5py.File('Xtest_rs.h5', 'w')\n",
        "h55.create_dataset('Xtest_rs', data=Xtest_rs)\n",
        "h55.close()\n",
        "\n",
        "#Storing the h5 files to GDrive\n",
        "!cp ./Xtest_rs.h5 ./gdrive/My\\ Drive/Pickle_Files"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AsA_AgUwqyf9",
        "outputId": "7e4509a6-9443-4e60-c53c-75dd76868e4f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "# Reading Xtrain_rs data from h5 files\n",
        "import h5py\n",
        "Xrsh5 = h5py.File('/content/gdrive/My Drive/Pickle_Files/Xtrain_rs.h5','r')\n",
        "Xtrain_rs = Xrsh5['Xtrain_rs']\n",
        "Xtrain_rs.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(600000, 2381)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3yzcRH4qyVg",
        "outputId": "99535da5-d90b-4090-8f2c-77848ba7542a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "# Reading Xtest_rs data from h5 files\n",
        "import h5py\n",
        "Xtrsh5 = h5py.File('/content/gdrive/My Drive/Pickle_Files/Xtest_rs.h5','r')\n",
        "Xtest_rs = Xtrsh5['Xtest_rs']\n",
        "Xtest_rs.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(200000, 2381)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TPNEf-Kd3tsW"
      },
      "source": [
        "## Model Arcitecture & Training:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ZKXIPIJ3S3_"
      },
      "source": [
        "#Function for the model\n",
        "def myModel():\n",
        "\n",
        "    import tensorflow as tf\n",
        "    from tensorflow import keras\n",
        "    from tensorflow.keras import layers\n",
        "    from tensorflow.keras.models import Sequential\n",
        "    from keras import regularizers\n",
        "    tf.compat.v1.disable_eager_execution()\n",
        "\n",
        "    #Model architecture\n",
        "    model = Sequential()\n",
        "    model.add(layers.InputLayer(input_shape=(2381,)))\n",
        "    model.add(layers.Dropout(0.2))\n",
        "    model.add(layers.Dense(units = 1000, activation = tf.nn.relu, activity_regularizer=regularizers.l2(0.01)))\n",
        "    model.add(layers.Dropout(0.5))\n",
        "    model.add(layers.Dense(units = 1, activation=tf.nn.sigmoid))\n",
        "    print(model.summary())\n",
        "\n",
        "    #model compilation\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    model.save('my_model.h5')\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kAGbdm0saCKL",
        "outputId": "6d552ec5-f9cc-41df-82b4-4ed20e36e0e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387
        }
      },
      "source": [
        "model = myModel()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:1666: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dropout (Dropout)            (None, 2381)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1000)              2382000   \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 1000)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 1001      \n",
            "=================================================================\n",
            "Total params: 2,383,001\n",
            "Trainable params: 2,383,001\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6aNmXj_5f8q",
        "outputId": "507bde96-ac64-4e23-a873-1fcbd4a1f13f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "#Training the model on 1 epoch\n",
        "history = model.fit(Xtrain_rs, y_train,\n",
        "                batch_size=256, shuffle=\"batch\",\n",
        "                epochs=1,\n",
        "                validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 480000 samples, validate on 120000 samples\n",
            "Epoch 1/1\n",
            "480000/480000 [==============================] - 75s 157us/step - loss: 199371956481915.2188 - accuracy: 0.5161 - val_loss: 1433708113807.5051 - val_accuracy: 0.3903\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0bX1X32xLri",
        "outputId": "38669a21-ae8a-4fa2-ceed-343074e13a91",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history = model.fit(Xtrain_rs, y_train,\n",
        "                batch_size=256, shuffle=\"batch\",\n",
        "                epochs=30,\n",
        "                validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 480000 samples, validate on 120000 samples\n",
            "Epoch 1/30\n",
            "480000/480000 [==============================] - 75s 156us/step - loss: 6178487812691.4307 - accuracy: 0.5247 - val_loss: 1969192253130.7263 - val_accuracy: 0.4556\n",
            "Epoch 2/30\n",
            "480000/480000 [==============================] - 76s 158us/step - loss: 1058981049957.0898 - accuracy: 0.5552 - val_loss: 3813439811382.9297 - val_accuracy: 0.4401\n",
            "Epoch 3/30\n",
            "480000/480000 [==============================] - 76s 158us/step - loss: 229784464899.2173 - accuracy: 0.5377 - val_loss: 2560687258697.7104 - val_accuracy: 0.4306\n",
            "Epoch 4/30\n",
            "480000/480000 [==============================] - 76s 158us/step - loss: 1016042836667.2339 - accuracy: 0.5256 - val_loss: 574407725213.3739 - val_accuracy: 0.4072\n",
            "Epoch 5/30\n",
            "480000/480000 [==============================] - 76s 158us/step - loss: 105944078490.9681 - accuracy: 0.5293 - val_loss: 701150794838.2307 - val_accuracy: 0.4175\n",
            "Epoch 6/30\n",
            "480000/480000 [==============================] - 76s 158us/step - loss: 39826254685.3327 - accuracy: 0.5111 - val_loss: 256010935122.9343 - val_accuracy: 0.4479\n",
            "Epoch 7/30\n",
            "480000/480000 [==============================] - 77s 161us/step - loss: 49011224045.6871 - accuracy: 0.5085 - val_loss: 3021691767575.7310 - val_accuracy: 0.4261\n",
            "Epoch 8/30\n",
            "480000/480000 [==============================] - 76s 158us/step - loss: 104332267364.9166 - accuracy: 0.5078 - val_loss: 545956168777.0072 - val_accuracy: 0.4284\n",
            "Epoch 9/30\n",
            "480000/480000 [==============================] - 76s 158us/step - loss: 50759298974.8968 - accuracy: 0.5075 - val_loss: 804209375067.8447 - val_accuracy: 0.4227\n",
            "Epoch 10/30\n",
            "480000/480000 [==============================] - 80s 166us/step - loss: 339979163342.6208 - accuracy: 0.5052 - val_loss: 400114026152.0847 - val_accuracy: 0.4240\n",
            "Epoch 11/30\n",
            "480000/480000 [==============================] - 76s 158us/step - loss: 342160312177.5456 - accuracy: 0.5059 - val_loss: 458486425814.5881 - val_accuracy: 0.4387\n",
            "Epoch 12/30\n",
            "480000/480000 [==============================] - 75s 157us/step - loss: 701877176294.9227 - accuracy: 0.5055 - val_loss: 135395854613.2970 - val_accuracy: 0.4427\n",
            "Epoch 13/30\n",
            "480000/480000 [==============================] - 77s 160us/step - loss: 1870140593754.5503 - accuracy: 0.5088 - val_loss: 143314214819.6264 - val_accuracy: 0.4518\n",
            "Epoch 14/30\n",
            "480000/480000 [==============================] - 76s 157us/step - loss: 261664778228.1376 - accuracy: 0.5122 - val_loss: 1053137208764.1531 - val_accuracy: 0.4460\n",
            "Epoch 15/30\n",
            "480000/480000 [==============================] - 76s 159us/step - loss: 59661257698.9393 - accuracy: 0.5099 - val_loss: 6802059700625.0752 - val_accuracy: 0.4433\n",
            "Epoch 16/30\n",
            "480000/480000 [==============================] - 77s 160us/step - loss: 646433572171.8712 - accuracy: 0.5105 - val_loss: 4541052554838.7188 - val_accuracy: 0.4452\n",
            "Epoch 17/30\n",
            "480000/480000 [==============================] - 76s 158us/step - loss: 189729421627.3615 - accuracy: 0.5154 - val_loss: 1242129291808.7312 - val_accuracy: 0.4493\n",
            "Epoch 18/30\n",
            "480000/480000 [==============================] - 75s 157us/step - loss: 1364475557234.0129 - accuracy: 0.5171 - val_loss: 1989266234658.7402 - val_accuracy: 0.4478\n",
            "Epoch 19/30\n",
            "480000/480000 [==============================] - 77s 160us/step - loss: 1415480678417.3452 - accuracy: 0.5155 - val_loss: 449924351412.7711 - val_accuracy: 0.4534\n",
            "Epoch 20/30\n",
            "480000/480000 [==============================] - 76s 158us/step - loss: 197156019379.8801 - accuracy: 0.5178 - val_loss: 1683445315006.3015 - val_accuracy: 0.4563\n",
            "Epoch 21/30\n",
            "480000/480000 [==============================] - 74s 154us/step - loss: 37020623782.0104 - accuracy: 0.5202 - val_loss: 1846134533084.9065 - val_accuracy: 0.4560\n",
            "Epoch 22/30\n",
            "480000/480000 [==============================] - 74s 154us/step - loss: 202639031855.1043 - accuracy: 0.5175 - val_loss: 964622513682.7982 - val_accuracy: 0.4506\n",
            "Epoch 23/30\n",
            "480000/480000 [==============================] - 76s 158us/step - loss: 16942802998.9931 - accuracy: 0.5168 - val_loss: 486390543683.4103 - val_accuracy: 0.4592\n",
            "Epoch 24/30\n",
            "480000/480000 [==============================] - 74s 154us/step - loss: 1782897617438.5427 - accuracy: 0.5177 - val_loss: 1057376023146.0570 - val_accuracy: 0.4548\n",
            "Epoch 25/30\n",
            "480000/480000 [==============================] - 74s 155us/step - loss: 6324107412755.8467 - accuracy: 0.5195 - val_loss: 908728256234.3539 - val_accuracy: 0.4615\n",
            "Epoch 26/30\n",
            "480000/480000 [==============================] - 75s 156us/step - loss: 135793908627.4476 - accuracy: 0.5193 - val_loss: 2061703311421.6003 - val_accuracy: 0.4576\n",
            "Epoch 27/30\n",
            "480000/480000 [==============================] - 74s 155us/step - loss: 72855577711.3204 - accuracy: 0.5158 - val_loss: 924201204232.3602 - val_accuracy: 0.4567\n",
            "Epoch 28/30\n",
            "480000/480000 [==============================] - 74s 155us/step - loss: 757651698265.1063 - accuracy: 0.5158 - val_loss: 1068298676362.8690 - val_accuracy: 0.4551\n",
            "Epoch 29/30\n",
            "480000/480000 [==============================] - 76s 158us/step - loss: 67442393709.6003 - accuracy: 0.5154 - val_loss: 2266757227566.1035 - val_accuracy: 0.4539\n",
            "Epoch 30/30\n",
            "480000/480000 [==============================] - 74s 155us/step - loss: 485824225874.6187 - accuracy: 0.5156 - val_loss: 1446379017887.5652 - val_accuracy: 0.4612\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bg4sROzAX6lf"
      },
      "source": [
        "## Model Testing:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XyQp8WrpYBzY",
        "outputId": "5c9fb1a1-ad3f-459f-9fef-7f2e71da74b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# testing the model\n",
        "\n",
        "score =model.evaluate(Xtest_rs,y_test)\n",
        "print(\"Training accuracy:\", score[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "200000/200000 [==============================] - 35s 175us/step\n",
            "Training accuracy: 0.4422149956226349\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zz_J-0j2NauR"
      },
      "source": [
        "Now, lets save the model for future use."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBqnfO5DNYXk"
      },
      "source": [
        "# Save the model\n",
        "#model.save('my_model.h5')\n",
        "model.save_weights('my_model_weights.h5')\n",
        "\n",
        "#Storing the model to GDrive\n",
        "!cp ./my_model.h5 ./gdrive/My\\ Drive/Pickle_Files\n",
        "!cp ./my_model_weights.h5 ./gdrive/My\\ Drive/Pickle_Files"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6VWp3qzSOEZ6"
      },
      "source": [
        "# save neural network structure to JSON (no weights)\n",
        "model_json = model.to_json()\n",
        "with open(\"mymodeljson.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "\n",
        "model.save_weights(\"my_model-weights.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9RuDAKif17za"
      },
      "source": [
        "The below set of code is a a function that takes a PE file as its argument, runs it through the trained model, and returns the output i.e., 1 for Malware or 0 for Benign."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9ZQ-eXWxiby",
        "outputId": "96d91f8c-594c-4bae-f1ae-cdaa5852fd2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        }
      },
      "source": [
        "!wget https://repo.anaconda.com/archive/Anaconda3-2020.02-Windows-x86_64.exe"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-04-28 03:17:13--  https://repo.anaconda.com/archive/Anaconda3-2020.02-Windows-x86_64.exe\n",
            "Resolving repo.anaconda.com (repo.anaconda.com)... 104.16.131.3, 104.16.130.3, 2606:4700::6810:8303, ...\n",
            "Connecting to repo.anaconda.com (repo.anaconda.com)|104.16.131.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 488908696 (466M) [application/octet-stream]\n",
            "Saving to: ‘Anaconda3-2020.02-Windows-x86_64.exe’\n",
            "\n",
            "Anaconda3-2020.02-W 100%[===================>] 466.26M   201MB/s    in 2.3s    \n",
            "\n",
            "2020-04-28 03:17:15 (201 MB/s) - ‘Anaconda3-2020.02-Windows-x86_64.exe’ saved [488908696/488908696]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HS_N5Gdc5BkI"
      },
      "source": [
        "def testPE(pe):\n",
        "  import ember\n",
        "  import numpy as np\n",
        "  import tensorflow as tf\n",
        "  from sklearn.preprocessing import RobustScaler\n",
        "  rs = RobustScaler()\n",
        "\n",
        "  #opening the downloaded PE file\n",
        "  testpe = open(pe, \"rb\").read()\n",
        "  #Feature extractor class of the ember project\n",
        "  extract = ember.PEFeatureExtractor()\n",
        "  data = extract.feature_vector(testpe) #vectorizing the extracted features\n",
        "  scaled_data = rs.fit_transform([data])\n",
        "  Xdata = np.reshape(scaled_data,(1, 2381))\n",
        "\n",
        "  model = tf.keras.models.load_model('my_model.h5')\n",
        "  pred = model.predict_classes(Xdata)\n",
        "\n",
        "  return pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBX-cJolozfG",
        "outputId": "f5a6a19e-1921-4467-82d5-7cec04ec3074",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83
        }
      },
      "source": [
        "testPE(\"Anaconda3-2020.02-Windows-x86_64.exe\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: EMBER feature version 2 were computed using lief version 0.9.0-\n",
            "WARNING:   lief version 0.10.1-bfe5414 found instead. There may be slight inconsistencies\n",
            "WARNING:   in the feature calculations.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XAQVnkXDZC36"
      },
      "source": [
        "The model predicted that Anaconda PE file as Benign"
      ]
    }
  ]
}